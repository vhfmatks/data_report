"""
ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ìƒì„± ëª¨ë“ˆ
"""

import json
from typing import Dict, Any
from src.data.loader import convert_to_serializable
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import streamlit as st
import numpy as np
from src.utils.helpers import filter_unwanted_languages

def generate_insights(df: pd.DataFrame, schema: Dict, analysis_results: Dict, llm) -> str:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¡œë¶€í„° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ"""
    
    try:
        # 1. ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        context = {
            "ë¶„ì„_ëª©ì ": st.session_state.get("purpose", "ëª©ì ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ"),
            "ë³´ê³ ì„œ_ì£¼ì œ": st.session_state.get("topic", "ì£¼ì œê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ"),
            "ë¶„ì„_ê³„íš": st.session_state.get("analysis_plan", "ê³„íšì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ"),
            "ë°ì´í„°_ì •ë³´": {
                "ì „ì²´_í–‰ìˆ˜": len(df),
                "ì „ì²´_ì»¬ëŸ¼ìˆ˜": len(df.columns),
                "ë³€ìˆ˜_ì •ë³´": {
                    col: {
                        "ì´ë¦„": info.get("display_name", col),
                        "ì„¤ëª…": info.get("description", ""),
                        "ë°ì´í„°íƒ€ì…": info["data_type"]
                    } for col, info in schema.items()
                }
            }
        }

        # 2. ë¶„ì„ ê²°ê³¼ ìš”ì•½
        analysis_summary = {
            "ìˆ˜ì¹˜í˜•_ë³€ìˆ˜": {},
            "ë²”ì£¼í˜•_ë³€ìˆ˜": {},
            "ì‹œê³„ì—´_ë³€ìˆ˜": {},
            "ìƒê´€ê´€ê³„": []
        }

        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
        for col, info in schema.items():
            if info["data_type"] == "numeric" and col in analysis_results:
                stats = analysis_results[col].get("ê¸°ë³¸í†µê³„", {})
                analysis_summary["ìˆ˜ì¹˜í˜•_ë³€ìˆ˜"][info.get("display_name", col)] = {
                    "í‰ê· ": stats.get("í‰ê· ", 0),
                    "ì¤‘ì•™ê°’": stats.get("ì¤‘ì•™ê°’", 0),
                    "í‘œì¤€í¸ì°¨": stats.get("í‘œì¤€í¸ì°¨", 0),
                    "ì´ìƒì¹˜_ë¹„ìœ¨": analysis_results[col].get("ì´ìƒì¹˜", {}).get("ë¹„ìœ¨", 0)
                }

        # ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
        for col, info in schema.items():
            if info["data_type"] == "categorical" and col in analysis_results:
                value_counts = analysis_results[col].get("ê³ ìœ ê°’", {})
                top_categories = dict(list(value_counts.get("ë¶„í¬", {}).items())[:3])
                analysis_summary["ë²”ì£¼í˜•_ë³€ìˆ˜"][info.get("display_name", col)] = {
                    "ê³ ìœ ê°’_ìˆ˜": value_counts.get("ê°œìˆ˜", 0),
                    "ìƒìœ„_ë²”ì£¼": top_categories
                }

        # ì‹œê³„ì—´ ë³€ìˆ˜ ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
        for col, info in schema.items():
            if info["data_type"] == "datetime" and col in analysis_results:
                period = analysis_results[col].get("ê¸°ê°„", {})
                analysis_summary["ì‹œê³„ì—´_ë³€ìˆ˜"][info.get("display_name", col)] = {
                    "ì‹œì‘": period.get("ì‹œì‘", "N/A"),
                    "ì¢…ë£Œ": period.get("ì¢…ë£Œ", "N/A"),
                    "ê¸°ê°„_ì¼ìˆ˜": period.get("ê¸°ê°„", {}).get("ì¼ìˆ˜", 0)
                }

        # ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
        if "ìƒê´€ê´€ê³„" in analysis_results:
            analysis_summary["ìƒê´€ê´€ê³„"] = [
                {
                    "ë³€ìˆ˜ìŒ": f"{corr['ë³€ìˆ˜1']}-{corr['ë³€ìˆ˜2']}",
                    "ìƒê´€ê³„ìˆ˜": corr["ìƒê´€ê³„ìˆ˜"],
                    "ê°•ë„": corr.get("ê°•ë„", "ì •ë³´ ì—†ìŒ")
                }
                for corr in analysis_results["ìƒê´€ê´€ê³„"][:5]  # ìƒìœ„ 5ê°œë§Œ í¬í•¨
            ]

        # 3. LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ì˜ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•˜ë©°, ì˜ì–´ëŠ” ê¼­ í•„ìš”í•œ ì „ë¬¸ìš©ì–´ì—ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
ì ˆëŒ€ë¡œ ì¤‘êµ­ì–´, ì¼ë³¸ì–´, ëŸ¬ì‹œì•„ì–´ ë“± ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¬ì¸µì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”.

[ë¶„ì„ ì»¨í…ìŠ¤íŠ¸]
ë¶„ì„ ëª©ì : {context["ë¶„ì„_ëª©ì "]}
ë³´ê³ ì„œ ì£¼ì œ: {context["ë³´ê³ ì„œ_ì£¼ì œ"]}

[ë¶„ì„ ê³„íš]
{context["ë¶„ì„_ê³„íš"]}

[ë°ì´í„° ê¸°ë³¸ ì •ë³´]
- ì „ì²´ ë°ì´í„°: {context["ë°ì´í„°_ì •ë³´"]["ì „ì²´_í–‰ìˆ˜"]:,}í–‰ Ã— {context["ë°ì´í„°_ì •ë³´"]["ì „ì²´_ì»¬ëŸ¼ìˆ˜"]}ì—´

[ë¶„ì„ ê²°ê³¼ ìš”ì•½]
1. ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ë¶„ì„:
{json.dumps(analysis_summary["ìˆ˜ì¹˜í˜•_ë³€ìˆ˜"], ensure_ascii=False, indent=2)}

2. ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„ì„:
{json.dumps(analysis_summary["ë²”ì£¼í˜•_ë³€ìˆ˜"], ensure_ascii=False, indent=2)}

3. ì‹œê³„ì—´ ë¶„ì„:
{json.dumps(analysis_summary["ì‹œê³„ì—´_ë³€ìˆ˜"], ensure_ascii=False, indent=2)}

4. ì£¼ìš” ìƒê´€ê´€ê³„:
{json.dumps(analysis_summary["ìƒê´€ê´€ê³„"], ensure_ascii=False, indent=2)}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

1. í•µì‹¬ ë°œê²¬ì‚¬í•­ (Key Findings)
   - ë°ì´í„°ì—ì„œ ë°œê²¬ëœ ê°€ì¥ ì¤‘ìš”í•œ íŒ¨í„´ì´ë‚˜ íŠ¸ë Œë“œ
   - ì˜ˆìƒê³¼ ë‹¤ë¥¸ íŠ¹ì´ì ì´ë‚˜ ì´ìƒì¹˜
   - ë³€ìˆ˜ ê°„ ì¤‘ìš”í•œ ê´€ê³„

2. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ (Business Insights)
   - ë°œê²¬ì‚¬í•­ì´ ë¹„ì¦ˆë‹ˆìŠ¤ì— ì£¼ëŠ” ì˜ë¯¸
   - ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆì‚¬í•­
   - ê°œì„  ê¸°íšŒ

3. ì¶”ê°€ ë¶„ì„ í•„ìš”ì‚¬í•­ (Further Analysis)
   - ë” ê¹Šì´ ìˆëŠ” ë¶„ì„ì´ í•„ìš”í•œ ì˜ì—­
   - ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ì´ í•„ìš”í•œ ë¶€ë¶„
   - ê²€ì¦ì´ í•„ìš”í•œ ê°€ì„¤

ê° ì„¹ì…˜ì—ì„œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ê·¼ê±°ë¥¼ í¬í•¨í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ë©°, ì˜ì–´ëŠ” ê¼­ í•„ìš”í•œ ì „ë¬¸ìš©ì–´ì—ë§Œ ì‚¬ìš©í•´ì£¼ì„¸ìš”."""

        # 4. LLMì„ í†µí•œ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        response = llm.invoke(prompt)
        response_content = filter_unwanted_languages(response.content)
        
        # 5. ì‹œê°í™” ë° ìƒì„¸ ë¶„ì„ ì¶”ê°€
        st.write("### ğŸ“Š ì£¼ìš” ì‹œê°í™”")
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ì˜ ë¶„í¬ ë¹„êµ
        numeric_cols = [col for col, info in schema.items() if info["data_type"] == "numeric"]
        if len(numeric_cols) > 0:
            st.write("#### ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ë¶„í¬ ë¹„êµ")
            fig, axes = plt.subplots(1, len(numeric_cols), figsize=(5*len(numeric_cols), 4))
            if len(numeric_cols) == 1:
                axes = [axes]
            
            for ax, col in zip(axes, numeric_cols):
                sns.boxplot(data=df, y=col, ax=ax)
                ax.set_title(schema[col].get("display_name", col))
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

        # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
        if len(numeric_cols) > 1:
            st.write("#### ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„")
            corr_matrix = df[numeric_cols].corr()
            
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(corr_matrix, 
                       annot=True, 
                       cmap='RdYlBu_r',
                       center=0,
                       vmin=-1,
                       vmax=1,
                       ax=ax)
            plt.title("ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")
            st.pyplot(fig)
            plt.close()

        # ì‹œê³„ì—´ íŠ¸ë Œë“œ
        datetime_cols = [col for col, info in schema.items() if info["data_type"] == "datetime"]
        if datetime_cols and numeric_cols:
            st.write("#### ì‹œê³„ì—´ íŠ¸ë Œë“œ")
            fig, ax = plt.subplots(figsize=(12, 6))
            
            time_col = datetime_cols[0]
            value_col = numeric_cols[0]
            
            df_grouped = df.groupby(pd.to_datetime(df[time_col]).dt.to_period('M'))[value_col].mean()
            ax.plot(range(len(df_grouped)), df_grouped.values, marker='o')
            ax.set_xticks(range(len(df_grouped)))
            ax.set_xticklabels(df_grouped.index.astype(str), rotation=45)
            ax.set_title(f"{schema[value_col].get('display_name', value_col)} ì¶”ì´")
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

        # 6. LLM ì‘ë‹µ í‘œì‹œ
        st.write("### ë°ì´í„° ì¸ì‚¬ì´íŠ¸")
        st.markdown(response_content)
        
        return response_content
        
    except Exception as e:
        error_msg = f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        st.error(error_msg)
        return error_msg 